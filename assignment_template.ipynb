{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "conditional-nitrogen",
   "metadata": {},
   "source": [
    "# Python assignment\n",
    "\n",
    "\n",
    "|Name|SNR|ANR|\n",
    "|----|---|----|\n",
    "|Elena Tello Pe√±a|2077934|u224519|\n",
    "|Guillem Torres Antillach|2071298|u518906|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "based-tunisia",
   "metadata": {},
   "source": [
    "## Research question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "industrial-giving",
   "metadata": {},
   "source": [
    "How does economic development relate to water withdrawals? The possible answer to this question is that of an Environmental Kuznets Curve (EKC), we will try to elucidate whether this is true through the analysis of various datasets (both cross-sectional and panel data) and different approaches for performing them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuffed-reduction",
   "metadata": {},
   "source": [
    "## Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ancient-courage",
   "metadata": {},
   "source": [
    "We are now facing a global context of water resources crisis and its rates of consumption have even outpaced that of population growth. To properly tackle this issue, it is then necessary to estimate how water availability will be shapen in the future. In this sense, the analysis of data that is until now available sometimes shows an \"inverted U\" type relationship between economic growth and water withdrawals, which corresponds to the environmental equivalent of the Kuznets Curve (EKC). This shape would mean that when a country is in an early stage of economic development it will keep increasing its water use as long as it grows to the turning point (due to a higher deploy of industrial activities, higher consume, and other circumstances). When this point, the peak of the curve, is reached, the increase of economic development would help the country reduce this withdrawals, likely through technological advancements.\n",
    "\n",
    "Our purpose is then to study how Gross National Product per capita, as a proxy for economic development, influences water withdrawals and also to find whether the cited EKC relationship is actually found when studying the data, trying to prove that there might be a way to predict how economic development can be determinant for the reshaping of the water consumption patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laden-purse",
   "metadata": {},
   "source": [
    "## Data and results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hairy-arrangement",
   "metadata": {},
   "source": [
    "We first conduct a general statistical analysis of the available World Bank Data related to water withdrawals, including a function showing GDPpc and water withdrawals per capita for any country that is selected in the input, bar graphs to show the differences of water use per sector and several maps that depict the water withdrawals per country. \n",
    "\n",
    "In order to assess the probable existance of an EKC, we first perform GLS regressions on a cross-sectional dataset and then fixed and random effects regressions on panel data. For both cases there are several assumptions that must be taken into account. The common one is the hypothesis of homoskedasticity in the error term that is tested through White and Breusch-Pagan tests: if the hypothesis is rejected then there is evidence of heteroskedasticity, as it is concluded when performing every one of the models. For the panel data regressions, we also look for serial autocorrelation through the Durbin-Watson test and we find evidence of it in every case. Also, for the models that include a quadratic term, we estimate the turning point of the function.\n",
    "\n",
    "When implementing these regressions, we find that only the panel data ones show some degree of significance, especially the linear version of them. When adding the square term so as to prove the cited EKC relationship, only the agricultural sector water withdrawals show relevant results. \n",
    "\n",
    "This way, we cannot really conclude that the relationships that we study properly follow an EKC shape, but the reduced significance may be caused by other limitations as we will further detail in the conclusion section.\n",
    "In both apporaches the sensitivity of the analysis is tested through implementation for the same tools on different data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleased-treasury",
   "metadata": {},
   "source": [
    "### Overview of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaging-physics",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from shapely.geometry import Point\n",
    "import sys\n",
    "!{sys.executable} -m pip install mapclassify\n",
    "import sys\n",
    "!{sys.executable} -m pip install xlrd\n",
    "from shapely.geometry import Point\n",
    "import sys\n",
    "!{sys.executable} -m pip install folium\n",
    "import folium\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.diagnostic import het_breuschpagan\n",
    "import math\n",
    "!{sys.executable} -m pip install folium\n",
    "import xlrd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ethical-bedroom",
   "metadata": {},
   "source": [
    "## Example of Kuznets Curve\n",
    "Below we can see the case of Spain (if you use the function you can get any country that you want). In this case we see how water per capita withdrawals decrease as gdp per capita increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reasonable-making",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first two lines extract the data from the csv file and then merge it together using the inner join method. This method will return a dataframe that contains only the rows that share common characteristics \n",
    "gdppc = pd.read_csv(\"gdp-per-capita-worldbank.csv\")\n",
    "waterppc = pd.read_csv(\"water-withdrawals-per-capita.csv\")\n",
    "waterxgdp = gdppc.merge(waterppc, how = \"inner\")\n",
    "# this line will set the column Year as the index of the dataframe\n",
    "waterxgdp = waterxgdp.set_index('Year')\n",
    "waterxgdp\n",
    "fig, ax = plt.subplots(figsize=(18,5))\n",
    "# what this function does basically:\n",
    "# it takes a country of the dataframe, the one that the author wants to study (in this case India). then creates a time plot with two y axis, so you can compare the evolution of the two variables across time  \n",
    "def country(data):\n",
    "    ax.plot(data.index, data[\"GDP per capita, PPP (constant 2017 international $)\"], color = \"black\", label = \"GDP per capita\")\n",
    "    ax.set_xlabel(\"Time\")\n",
    "    ax.set_ylabel(\"GDP per capita, PPP (constant 2017 international $)\")\n",
    "    ax2 = ax.twinx()\n",
    "    ax2.plot(data.index, data[\"Total water withdrawal per capita\"], label = \"water per capita\")\n",
    "    ax2.set_ylabel(\"Total water withdrawal per capita\")\n",
    "    ax.legend()\n",
    "    ax2.legend(loc = 'upper right')\n",
    "    plt.title(\"Comparison of Total water withdrawal per capita and GDP per capita, PPP (constant 2017 international $) by country: \")\n",
    "    plt.show()\n",
    "# The reason behind this complicated way to retrieve the country, is that the countries are part of an specific column named Entity\n",
    "country(waterxgdp.loc[(waterxgdp[\"Entity\"]==\"Spain\")])\n",
    "print(waterxgdp.loc[(waterxgdp[\"Entity\"]==\"Spain\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electric-dryer",
   "metadata": {},
   "source": [
    "# Answers\n",
    "For the GLS regression we obtain the following turning points (in annual GDP per capita terms): <br /> \n",
    "Total water withdrawal per capita: **10.51 dollars** <br /> \n",
    "Industry water withdrawal: **157 dollars** <br /> \n",
    "Agriculture water withdrawal: **32 dollars** <br /> \n",
    "Domestic water withdrawal: **17 dollars** <br /> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "innocent-calvin",
   "metadata": {},
   "source": [
    "# Data:\n",
    "## Stacked Bar Plots:\n",
    "In the following bar plot what we can see is that the weight of agriculture has gone down in the recent years while the weight of Industrial and Domestic has increased over the years. What this could mean is that more and more countries are starting to develop and they are leaving the low income area. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sublime-jacksonville",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reads the data from excel and transforms it into a dataframe\n",
    "waterAgr = pd.read_excel(\"AgriculturalWater.xls\", engine = \"xlrd\", header = 3 )\n",
    "# drops rows with na values\n",
    "waterAgr = waterAgr.dropna(0)\n",
    "# calculates the mean of every row\n",
    "avgwater = pd.DataFrame(waterAgr.mean(axis=0))\n",
    "waterInd = pd.read_excel(\"IndustrialWater.xls\", engine = \"xlrd\", header = 3 )\n",
    "waterInd = waterInd.dropna(0)\n",
    "avgwater[\"Industry\"] = pd.DataFrame(waterInd.mean(axis=0))\n",
    "waterDom = pd.read_excel(\"domestic_water.xls\", engine = \"xlrd\", header = 3 )\n",
    "waterDom = waterDom.dropna(0)\n",
    "avgwater[\"Domestic\"] = pd.DataFrame(waterDom.mean(axis=0))\n",
    "# this line will store the first three columns of the database\n",
    "avgwater = avgwater.iloc[: , :3]\n",
    "# This chunk  of code creates the plot seen below.\n",
    "fig, ax = plt.subplots(figsize=(18,5))\n",
    "ax.bar(avgwater.index, avgwater[0], label = \"Agriculture\")\n",
    "ax.bar(avgwater.index, avgwater[\"Domestic\"], bottom=avgwater[0], label = \"Domestic\")\n",
    "ax.bar(avgwater.index, avgwater[\"Industry\"], bottom=avgwater[0]+avgwater[\"Domestic\"], label = \"Industry\")\n",
    "ax.set_xticklabels(avgwater.index, rotation = 90)\n",
    "ax.set_ylabel(\"Percentage of total water withdrawals used by each sector\")\n",
    "ax.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moral-encoding",
   "metadata": {},
   "source": [
    "## Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "delayed-being",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "#what this line of code does is the following: alphabethically sorts the dataframe world based on the unicode \"NFKD\" format and then resets the index.\n",
    "#we call iloc because the code inside the [] will return a series of integers that need to be reordered\n",
    "world1 = (world.iloc[world['name'].str.normalize('NFKD').argsort()]).reset_index()\n",
    "#this line of code will drop Antartica, in the previous line what we did is to order alphabetically but also reorder the index\n",
    "world1.drop(4, inplace = True)\n",
    "water1 = pd.read_excel(\"TotalWaterMap.xls\", engine = \"xlrd\", header = 3 )\n",
    "# What this line of code does is obtain a list of countries that do not have an iso_a3 equal to the code of the excel database and then print the name of that country and what they have as an ISO code \n",
    "world1[~world1['iso_a3'].isin(list(water1['Country Code']))][['iso_a3', 'name']]\n",
    "#This line updates the Iso Codes of the countries that do not have a correct ISO code\n",
    "world1.loc[world1.name == 'France', 'iso_a3'] = 'FRA'\n",
    "world1.loc[world1.name == 'Norway', 'iso_a3'] = 'NOR'\n",
    "# in this line what we do is merge the two dataframes, we use how = left to maintain every row of the left dataframe which is the map in this case. \n",
    "water1 = world1.merge(water1,\n",
    "                            left_on = 'iso_a3',\n",
    "                            right_on = 'Country Code',\n",
    "                            how = 'left',)\n",
    "# what this function does: It takes a specific year of the dataframe water1, and also the dataframe itself and returns a colorised map that ranks the counntries by water withdrawals in cubic meters \n",
    "def newmap (date, water):\n",
    "    #water per capita in billion cubic meters\n",
    "    water[\"percapita\"] = date/(water[\"pop_est\"]/1000000000)\n",
    "    # what this two lines do is create a map where the color of each country is determined by the percapita value\n",
    "    axes = water.plot(column= \"percapita\",  edgecolor = \"black\", legend = True, legend_kwds={'shrink': 0.3}, cmap = \"OrRd\")\n",
    "    plt.rcParams[\"figure.figsize\"]=20,20\n",
    "    axes.set_axis_off()\n",
    "    plt.title(\"Annual freshwater withdrawals per capita cubic meters\")\n",
    "# this line sets the figure size of the map\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "newmap(water1[\"2017\"],water1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "green-jumping",
   "metadata": {},
   "outputs": [],
   "source": [
    "waterorder=water1.sort_values(by=['percapita'], ascending = False)\n",
    "waterorder.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exciting-clearance",
   "metadata": {},
   "outputs": [],
   "source": [
    "waterInd = pd.read_excel(\"IndustrialWater.xls\", engine = \"xlrd\", header = 3 )\n",
    "waterDom = pd.read_excel(\"domestic_water.xls\", engine = \"xlrd\", header = 3 )\n",
    "waterAgr = pd.read_excel(\"AgriculturalWater.xls\", engine = \"xlrd\", header = 3 )\n",
    "# what this function does: it takes any year and the database that the author wants to collect information from, then it is merged with the map of the world of geopandas \n",
    "# what is singular of this map is the use of the if statement to change the title that is returned, we do this because we want to get information from three databases and we want to get a correct title for each of them. \n",
    "def newsectormap (date, water):\n",
    "    water1 = world1.merge(water,\n",
    "                            left_on = 'iso_a3',\n",
    "                            right_on = 'Country Code',\n",
    "                            how = 'left',)\n",
    "    axes = water1.plot(column= date,  edgecolor = \"black\", legend = True, legend_kwds={'shrink': 0.3}, cmap = \"OrRd\")\n",
    "    axes.set_axis_off()\n",
    "    if water is waterInd:\n",
    "        return plt.title(\"Annual freshwater withdrawals, Industry (% of total freshwater withdrawal \" + date)\n",
    "    if water is waterAgr:\n",
    "        return plt.title(\"Annual freshwater withdrawals, Agriculture (% of total freshwater withdrawal \" + date)\n",
    "    if water is waterDom: \n",
    "        return plt.title(\"Annual freshwater withdrawals, Domestic (% of total freshwater withdrawal \" + date)\n",
    "    return none\n",
    "    plt.rcParams[\"figure.figsize\"]=20,20\n",
    "    plt.show()\n",
    "\n",
    "newsectormap(\"2012\", waterInd)\n",
    "newsectormap(\"2012\", waterAgr)\n",
    "newsectormap(\"2012\", waterDom)\n",
    "# this line sorts the value of the Agricultural water dataframe and gives us the top 5 countries that have a higher percentage of their use in this sector\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "failing-michigan",
   "metadata": {},
   "source": [
    "### Overview of the Sectors:\n",
    "In the year 2017 (we take this year because we do the regressions based on this specific year). We see big differences between the uses that country make of their water. Starting with the Industry one, we see countries using up to 96 of their total water withdrawals in this sector. Also in this sector we see more mix between developed countries (Estonia, Netherlands, Germany) and countries that are developing (Jamaica). On the other hand, we have the Agriculture sector, here we find that the top 5 share a specific characteristic: They are extremely underdeveloped. Finally we have the domestic sector, here the top 5 has also similar characteristics, all of them are small countries with no important industry and there economy is focused on the service sector (Tourism and Banking mostly)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satellite-invalid",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(waterInd.sort_values(by=['2017'], ascending = False).head())\n",
    "print(waterAgr.sort_values(by=['2017'], ascending = False).head())\n",
    "print(waterDom.sort_values(by=['2017'], ascending = False).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "czech-transportation",
   "metadata": {},
   "source": [
    "### GLS Regression Analysis\n",
    "We will use the following data:\n",
    "Total water withdrawals per capita, Annual freshwater withdrawals Industry (% of total freshwater withdrawal), Annual freshwater withdrawals Agriculture (% of total freshwater withdrawals), Annual freshwater withdrawals, Domestic (% of total freshwater withdrawal and GDP per capita, PPP (constant 2017 international dollars). The reason that we use this databases is to get a better picture of how countries differ in their water uses, and also try to explain the different turning points that we get in the results. As an example: when a country starts to develop, it increases it's use of industrial water and domestic while the Agricultural one diminishes. <br />\n",
    "The total withdrawals and GDP are in per capita terms while the Industry, Agriculture and Domestic are in percentage terms, the reason behing this is that Industry, Agriculture and Domestic were not available. <br />\n",
    "To try an answer the question we will two econometric approaches: <br />\n",
    "The first one is a cross sectional GLS. We use a reduced form with only one explanatory variable in this case GDP (in both linear and squared versions), which means we can only test for correlations not causation, we do this following the advide of the existing literature: \\begin{equation} Water_i = \\beta_0 + \\beta_1GDP_i + \\beta_2GDP_i + \\epsilon_i \\end{equation} <br />\n",
    "The form of the regression is log log, we do it this way to correct for possible outliers in the data.\n",
    "To perform a correct analysis what we do first is test for heteroscedasticity, using the breusch pagan test.\n",
    "As we will see every sector rejects the null hypothesis meaning that we have heteroscedasticity.\n",
    "After we have perform the GLS regression and obtained the coefficients we will then proceed and calculate the turning points of each sector.   \n",
    "To calculate the turning use we will use the formula proposed by Song Tao(2008): \\begin{equation} T=\n",
    "e^{-\\beta_1/(2*\\beta_2)} \\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enormous-oxygen",
   "metadata": {},
   "source": [
    "### Assumptions for the model:\n",
    "We have three main assumptions for the GLS regression: <br />\n",
    "**1st**: We perform a GLS to account for the Heteroscedasticity that is found in the data. waterInd.sort_values <br />\n",
    "**2nd**:For the explanatory variables (GDP), we take the mean value of a period instead of taking a single year (as we do with water), we do this because we want to evaluate the turning point of the economy. <br />\n",
    "**3rd**: The year that we choose for total water withdrawals changes from the one we took in the sector, the reason why is the unavailability of the data for that year. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silent-diabetes",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdppc.rename(columns={'Country Name': 'Entity'}, inplace=True)\n",
    "gdppc = gdppc.pivot(index='Entity', columns='Year', values='GDP per capita, PPP (constant 2017 international $)')\n",
    "waterppc = waterppc.pivot(index='Entity', columns='Year', values='Total water withdrawal per capita')\n",
    "waterppc = waterppc.reset_index()\n",
    "gdppc = gdppc.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "packed-journalism",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdppc.rename(columns={'Country Name': 'Entity'}, inplace=True)\n",
    "gdppc['mean'] = gdppc.mean(axis=1)\n",
    "gdppc[\"lGDPxc\"] = np.log10(gdppc[\"mean\"])\n",
    "gdppc[\"lGDPxcsq\"] = np.log10(gdppc[\"mean\"])**2\n",
    "waterpxc = waterppc.merge(gdppc, on = \"Entity\", how = \"left\" )\n",
    "waterpxc = waterpxc.fillna(1)\n",
    "\n",
    "\n",
    "def econometrics_water(water):\n",
    "    waterpxc[\"newwater\"] = np.log10(water)\n",
    "    X = pd.DataFrame({\"GDP\": np.log10(waterpxc[\"lGDPxc\"]), \"GDP2\": waterpxc[\"lGDPxcsq\"]})\n",
    "    f ='newwater~X'\n",
    "    breusch_model = ols(formula=f, data=waterpxc).fit()\n",
    "    bp_test = het_breuschpagan(breusch_model.resid, X)\n",
    "    labels = [\"Total Water Withdrawals LM Statistic\", \"LM-Test p-value\", \"F-Statistic\", \"F-Test, p-value\"]\n",
    "    print( labels, bp_test)\n",
    "    X = pd.DataFrame({\"GDP\": waterpxc[\"lGDPxc\"], \"GDP2\": waterpxc[\"lGDPxcsq\"]})\n",
    "    X = sm.add_constant(X)\n",
    "    Y = waterpxc[\"newwater\"]\n",
    "    GLS_MU_sigma = sm.GLS(Y,X)\n",
    "    Fit_mu = GLS_MU_sigma.fit()\n",
    "    coefficient = Fit_mu.params\n",
    "    turning_point = np.exp(-coefficient[1]/(2*coefficient[2]))\n",
    "    print(Fit_mu.summary(), turning_point)\n",
    "    \n",
    "\n",
    "econometrics_water(waterpxc[\"2015_x\"])\n",
    "waterppc\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "white-april",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdpexcel = pd.read_excel(\"GDP2011_18.xls\", engine = \"xlrd\", header = 3 )\n",
    "water_sector = waterInd.merge(gdpexcel, on = \"Country Name\", how = \"left\")\n",
    "water_sector = water_sector.dropna(0)\n",
    "def econometrics_Ind(water):\n",
    "    water_sector[\"newwater\"] = np.log10(water)\n",
    "    water_sector[\"lGDPxc\"] = np.log10(water_sector[\"Average\"])\n",
    "    water_sector[\"lGDPxcsq\"] = water_sector[\"lGDPxc\"]**2\n",
    "    X = pd.DataFrame({\"GDP\": water_sector[\"lGDPxc\"], \"GDP2\": water_sector[\"lGDPxcsq\"]})\n",
    "    f ='newwater~X'\n",
    "    breusch_model = ols(formula=f, data=water_sector).fit()\n",
    "    bp_test = het_breuschpagan(breusch_model.resid, X)\n",
    "    labels = [\"Total Water Withdrawals LM Statistic\", \"LM-Test p-value\", \"F-Statistic\", \"F-Test, p-value\"]\n",
    "    print( labels, bp_test)\n",
    "    X = pd.DataFrame({\"GDP\": water_sector[\"lGDPxc\"], \"GDP2\": water_sector[\"lGDPxcsq\"]})\n",
    "    X = sm.add_constant(X)\n",
    "    Y = water_sector[\"newwater\"]\n",
    "    GLS_MU_sigma = sm.GLS(Y,X)\n",
    "    Fit_mu = GLS_MU_sigma.fit()\n",
    "    coefficient = Fit_mu.params\n",
    "    turning_point = np.exp(-coefficient[1]/(2*coefficient[2]))\n",
    "    print(Fit_mu.summary(), turning_point)\n",
    "    \n",
    "econometrics_Ind(water_sector[\"2017\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "julian-thumbnail",
   "metadata": {},
   "outputs": [],
   "source": [
    "water_sector = waterAgr.merge(gdpexcel, on = \"Country Name\", how = \"left\")\n",
    "water_sector = water_sector.dropna(0)\n",
    "def econometrics_Agr(water):\n",
    "    water_sector[\"newwater\"] = np.log10(water)\n",
    "    water_sector[\"lGDPxc\"] = np.log10(water_sector[\"Average\"])\n",
    "    water_sector[\"lGDPxcsq\"] = water_sector[\"lGDPxc\"]**2\n",
    "    X = pd.DataFrame({\"GDP\": water_sector[\"lGDPxc\"], \"GDP2\": water_sector[\"lGDPxcsq\"]})\n",
    "    f ='newwater~X'\n",
    "    breusch_model = ols(formula=f, data=water_sector).fit()\n",
    "    bp_test = het_breuschpagan(breusch_model.resid, X)\n",
    "    labels = [\"Total Water Withdrawals LM Statistic\", \"LM-Test p-value\", \"F-Statistic\", \"F-Test, p-value\"]\n",
    "    print( labels, bp_test)\n",
    "    X = pd.DataFrame({\"GDP\": water_sector[\"lGDPxc\"], \"GDP2\": water_sector[\"lGDPxcsq\"]})\n",
    "    X = sm.add_constant(X)\n",
    "    Y = water_sector[\"newwater\"]\n",
    "    GLS_MU_sigma = sm.GLS(Y,X)\n",
    "    Fit_mu = GLS_MU_sigma.fit()\n",
    "    coefficient = Fit_mu.params\n",
    "    turning_point = np.exp(-coefficient[1]/(2*coefficient[2]))\n",
    "    print(Fit_mu.summary(), turning_point)\n",
    "    \n",
    "econometrics_Agr(water_sector[\"2017\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appreciated-stand",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdppc=gdppc.rename(columns={\"Entity\": \"Country Name\"})\n",
    "waterpxc1 = waterDom.merge(gdppc, on = \"Country Name\", how = \"inner\" )\n",
    "waterpxc1 = waterpxc.fillna(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "literary-small",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def econometrics_Dom(water):\n",
    "    waterpxc1[\"newwater\"] = np.log10(water)\n",
    "    X = pd.DataFrame({\"GDP\": np.log10(waterpxc1[\"lGDPxc\"]), \"GDP2\": waterpxc1[\"lGDPxcsq\"]})\n",
    "    f ='newwater~X'\n",
    "    breusch_model = ols(formula=f, data=waterpxc1).fit()\n",
    "    bp_test = het_breuschpagan(breusch_model.resid, X)\n",
    "    labels = [\"Total Water Withdrawals LM Statistic\", \"LM-Test p-value\", \"F-Statistic\", \"F-Test, p-value\"]\n",
    "    print( labels, bp_test)\n",
    "    X = pd.DataFrame({\"GDP\": waterpxc1[\"lGDPxc\"], \"GDP2\": waterpxc1[\"lGDPxcsq\"]})\n",
    "    X = sm.add_constant(X)\n",
    "    Y = waterpxc1[\"newwater\"]\n",
    "    GLS_MU_sigma = sm.GLS(Y,X)\n",
    "    Fit_mu = GLS_MU_sigma.fit()\n",
    "    coefficient = Fit_mu.params\n",
    "    turning_point = np.exp(-coefficient[1]/(2*coefficient[2]))\n",
    "    print(Fit_mu.summary(), turning_point)\n",
    "\n",
    "econometrics_Dom(waterpxc1[2017]) \n",
    "gdppc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constitutional-story",
   "metadata": {},
   "source": [
    "### Turning point calculations\n",
    "For the GLS regression we obtain the following turning points (in annual GDP per capita terms): <br /> \n",
    "Total water withdrawal per capita: **10.51 dollars** <br /> \n",
    "Industry water withdrawal: **157 dollars** <br /> \n",
    "Agriculture water withdrawal: **32 dollars** <br /> \n",
    "Domestic water withdrawal: **1736 dollars** <br /> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secret-acrylic",
   "metadata": {},
   "source": [
    "# Sensitivity Analysis:\n",
    "Instead of taking 2017 and 2015, we take 2012 and 2010 respectively. <br />\n",
    "Total Water Witdrawals per capita:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applicable-bermuda",
   "metadata": {},
   "outputs": [],
   "source": [
    "econometrics_water(waterpxc[\"2010_x\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "innocent-judgment",
   "metadata": {},
   "source": [
    "Industrial Water Witdrawals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "difficult-surgery",
   "metadata": {},
   "outputs": [],
   "source": [
    "econometrics_Ind(water_sector[\"2012_x\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simple-mechanics",
   "metadata": {},
   "source": [
    "Agricultural Water Witdrawals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arbitrary-blast",
   "metadata": {},
   "outputs": [],
   "source": [
    "econometrics_Agr(water_sector[\"2012_x\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "received-script",
   "metadata": {},
   "source": [
    "Domestic Water Witdrawals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hispanic-taste",
   "metadata": {},
   "outputs": [],
   "source": [
    "econometrics_Dom(waterpxc1[2012]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marine-pixel",
   "metadata": {},
   "source": [
    "### Turning point calculations for the sensitivity analysis\n",
    "For the GLS regression we obtain the following turning points (in annual GDP per capita terms): <br /> \n",
    "Total water withdrawal per capita: **6 dollars** <br /> \n",
    "Industry water withdrawal: **25 dollars** <br /> \n",
    "Agriculture water withdrawal: **28 dollars** <br /> \n",
    "Domestic water withdrawal: **10832 dollars** <br /> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pregnant-mortgage",
   "metadata": {},
   "source": [
    "## PANEL DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cosmetic-woman",
   "metadata": {},
   "source": [
    "### INTRODUCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mechanical-healing",
   "metadata": {},
   "source": [
    "Now we proceed to carry out a panel data analysis. The purpose of this section is to further explore the EKC hypothesis through more accurate channels. Thanks to panel data we are able to reflect trends overtime, which is after all a key element of the EKC characteristics. Also, it helps to capture the variations that are likely to happen among nations due to geographical and climatic factors that may be behind differences in water use. \n",
    "We choose a more reduced database than in the previous step because panel data is not as widely available as cross-sectional data. This way, we choose 32 OECD countries to perform the study, also dividing water use by sectors: agricultural, domestic, and industrial. Although fixed effects regressions are better suited for the characteristics of these data, random effects are also taken into consideration so as to compare both regression approaches. The reason why fixed effects should be more convenient despite the final outcome in terms of significance, R-squared values or any other measure of statistical accuracy is due to the already mentioned fact that the entity intercept included in the fixed effects regressions allows for differences between water resource endowments that are likely to have an influence on water withdrawals, as well as climatic or state-specific factors that would determine the final water use. The equations for the panel fixed effect regressions would be as follows:\n",
    "\n",
    "$$WATER_{i}= \\beta_{0} + \\alpha_{i} + \\beta_{1}GDPpc_{it} + \\epsilon_{it}$$\n",
    "$$WATER_{i}= \\beta_{0} + \\alpha_{i} + \\beta_{1}GDPpc_{it} + \\beta_{2}{GDPpc^{2}_{it}}+ \\epsilon_{it}$$\n",
    "\n",
    "The variables WATER and GDPpc represent the logs of per capita annual water withdrawals in cubic meters and per capita gross domestic product in constant 2015 US$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bottom-coast",
   "metadata": {},
   "source": [
    "### CREATING THE DATASET: DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "victorian-implementation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#install packages\n",
    "!pip install wbdata\n",
    "!pip install linearmodels\n",
    "#import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "import wbdata as wb\n",
    "import seaborn as sns\n",
    "import numpy.linalg as la\n",
    "from scipy import stats\n",
    "from linearmodels import PanelOLS\n",
    "from linearmodels import RandomEffects\n",
    "from statsmodels.stats.diagnostic import het_white, het_breuschpagan\n",
    "from statsmodels.stats.stattools import durbin_watson\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minute-lending",
   "metadata": {},
   "source": [
    "We first create a subset with all 38 OECD countries to be analysed and with the years for which freshwater withdrawals are available. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fresh-beatles",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subsets of countries and years to be analyzed\n",
    "OECDcountries = ['AUS','AUT','BEL','CAN','CHL', 'COL','CRI','CZE','DNK','EST','FIN','FRA','DEU','GRC','HUN','ISL','IRL','ISR','ITA','JPN','KOR','LVA','LTU','LUX','MEX','NLD','NZL','NOR','POL','PRT','SVK','SVN','ESP','SWE','CHE','TUR','GBR','USA']\n",
    "selyears = ['1982','1987','1992','1997','2002','2007','2012','2007','2012','2017']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "herbal-maple",
   "metadata": {},
   "source": [
    "Making use of the world bank database, we will look for the necessary variables, which are named this way:\n",
    "\n",
    "-‚Äúwtrwth‚Äù: freshwater withdrawals, total (billion cubic meters)\\\n",
    "-‚Äúgdppc‚Äù: GDP per capita (constant 2015 US dollars)\\\n",
    "-‚Äúpop‚Äù: total population\\\n",
    "-‚Äúwtrwthag‚Äù: freshwater withdrawals, agriculture (percentage of total freshwater withdrawal)\\\n",
    "-‚Äúwtrwthdom‚Äù: freshwater withdrawals, domestic (percentage of total freshwater withdrawal)\\\n",
    "-‚Äúwtrwthind‚Äù: freshwater withdrawals, industrial (percentage of total freshwater withdrawal)\\\n",
    "\n",
    "The preliminary look for this database is thus displayed for the selected countries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offensive-excitement",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataframe building\n",
    "fwindicators = {\n",
    "                \"ER.H2O.FWTL.K3\" : \"wtrwth\",\n",
    "                \"NY.GDP.PCAP.KD\" : \"gdppc\", #GDP per capita (constant 2015 US$)\n",
    "                \"SP.POP.TOTL\" : \"pop\",\n",
    "                \"ER.H2O.FWAG.ZS\" : \"wtrwthag\",\n",
    "                \"ER.H2O.FWDM.ZS\" : \"wtrwthdom\",\n",
    "                \"ER.H2O.FWIN.ZS\" : \"wtrwthind\"}\n",
    "dfw = wb.get_dataframe(fwindicators, country=OECDcountries)\n",
    "\n",
    "dfw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weekly-headline",
   "metadata": {},
   "source": [
    "Then, we convert the water withdrawals variables to per capita values by dividing for the population values. For the sake of this matter, in the case of the sectorial variables, since they come in percentage, we first multiply by the previously per capita values of the general freshwater withdrawals. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuous-rolling",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creation of per capita variables in cubic meters\n",
    "dfw['wtrwthpc']=(dfw['wtrwth']/dfw['pop'])*1000000000 \n",
    "#Transformation of percentage to cubic meters per capita in the next three lines of code\n",
    "dfw['wtrwthagpc']=dfw['wtrwthag']*(dfw['wtrwth']/dfw['pop'])*10000000 \n",
    "dfw['wtrwthdompc']=dfw['wtrwthdom']*(dfw['wtrwth']/dfw['pop'])*10000000 \n",
    "dfw['wtrwthindpc']=dfw['wtrwthind']*(dfw['wtrwth']/dfw['pop'])*10000000\n",
    "dfw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infrared-fifteen",
   "metadata": {},
   "source": [
    "The index is reset in order to better manipulate the data frame and the date values are then converted into numeric format, also selecting the subset of years that were previously stated. The preview shows how missing values are progressively decreasing and a summary of the statistics for each variable is shown. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forward-soviet",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resetting the index in order to manipulate the dataframe\n",
    "dfw2=dfw.copy()\n",
    "dfw2.reset_index(inplace=True)\n",
    "dfw2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animal-details",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting the years subject of analysis\n",
    "dfw2['date']=pd.to_numeric(dfw2['date'])\n",
    "dfw_selyrs=dfw2[dfw2['date'].isin(pd.to_numeric(selyears))]\n",
    "dfw_selyrs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "common-appendix",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataframe summary statistics\n",
    "dfw.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attempted-dancing",
   "metadata": {},
   "source": [
    "Since it is more convenient to work with a balanced panel dataset, we look for missing values for both date and country index components. In the next step, we drop them out of the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corrected-request",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for missing values\n",
    "dfnowater=dfw_selyrs[dfw_selyrs[\"wtrwth\"].isnull()]\n",
    "dfnowater['date'].value_counts()\n",
    "dfnowater['country'].value_counts()\n",
    "dfnogdp=dfw_selyrs[dfw_selyrs[\"gdppc\"].isnull()]\n",
    "dfnogdp['date'].value_counts()\n",
    "dfnogdp['country'].value_counts()\n",
    "dfnopop=dfw_selyrs[dfw_selyrs[\"pop\"].isnull()]\n",
    "dfnopop['date'].value_counts()\n",
    "dfnopop['country'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nominated-knight",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop missing values and show balanced panel data\n",
    "dfw_full=dfw_selyrs.dropna()\n",
    "dfw_full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "copyrighted-holly",
   "metadata": {},
   "source": [
    "We can now see the total number of observations and the type of each variable included in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "married-setting",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Showing characteristics of the balanced data set\n",
    "dfw_full.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rapid-royalty",
   "metadata": {},
   "source": [
    "First of all, even if the dataset seems to be ready for the regression analysis, it is necessary to properly declare country and date as a multi-index component, otherwise the panel data analysis regression tool will not be able to identify the entity and time variable adequately. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breeding-sugar",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set multiindex for the regressions\n",
    "dfreg=dfw_full.copy()\n",
    "dfreg.set_index(['country','date'], inplace=True)\n",
    "dfreg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mobile-yesterday",
   "metadata": {},
   "source": [
    "##### Some graphs to further analyse the changes in the variables over time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mechanical-genetics",
   "metadata": {},
   "source": [
    "We perform several plots in order to specifically see the differences in GDPpc and water withdrawals (total and by sector) across time of some countries of our choice (in this case, we picked a European country, an Asian country and an American country; the concrete choice was purely made out of convinience, since France, Korea and United States present data for the whole time span). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "public-kitty",
   "metadata": {},
   "source": [
    "In the first graph we can see that Korea shows the steeper GDPpc growth curve, while United States and France economics are closer to stagnation, which is coherent with reality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eleven-april",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmani = dfreg.copy()\n",
    "dfmani.reset_index(inplace=True)\n",
    "dfmani = dfmani[dfmani['country'].isin(['France', 'United States', 'Korea, Rep.'])]\n",
    "dfmani.sort_values(['date', 'country'], inplace=True)\n",
    "dfmani.head()\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.lineplot(x='date', y='gdppc', hue='country', data=dfmani)\n",
    "plt.yscale('log')\n",
    "plt.legend(title='country', bbox_to_anchor=(1.05, 1), loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "green-confusion",
   "metadata": {},
   "source": [
    "In the case of water withdrawals per capita we can see that the United States is far above the others and we can see how Korea goes above France after 1996 approximatedly, likely due to its economic development. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extraordinary-willow",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmani = dfreg.copy()\n",
    "dfmani.reset_index(inplace=True)\n",
    "dfmani = dfmani[dfmani['country'].isin(['France', 'United States', 'Korea, Rep.'])]\n",
    "dfmani.sort_values(['date', 'country'], inplace=True)\n",
    "dfmani.head()\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.lineplot(x='date', y='wtrwthpc', hue='country', data=dfmani)\n",
    "plt.yscale('log')\n",
    "plt.legend(title='country', bbox_to_anchor=(1.05, 1), loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "independent-neighbor",
   "metadata": {},
   "source": [
    "In the next graph we see how United States and Korea are clearly more focused on agriculture than France is, given the levels of the functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dirty-workshop",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmani = dfreg.copy()\n",
    "dfmani.reset_index(inplace=True)\n",
    "dfmani = dfmani[dfmani['country'].isin(['France', 'United States', 'Korea, Rep.'])]\n",
    "dfmani.sort_values(['date', 'country'], inplace=True)\n",
    "dfmani.head()\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.lineplot(x='date', y='wtrwthagpc', hue='country', data=dfmani)\n",
    "plt.yscale('log')\n",
    "plt.legend(title='country', bbox_to_anchor=(1.05, 1), loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "european-primary",
   "metadata": {},
   "source": [
    "We now make a closer look on Korea's agricultural water withdrawals and see how this shape could resemble an EKC: the withdrawals maxed when economic development was growing at a higher rate and then started to decrease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "small-austin",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmani = dfreg.copy()\n",
    "dfmani.reset_index(inplace=True)\n",
    "dfmani = dfmani[dfmani['country'].isin(['Korea, Rep.'])]\n",
    "dfmani.sort_values(['date', 'country'], inplace=True)\n",
    "dfmani.head()\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.lineplot(x='date', y='wtrwthagpc', hue='country', data=dfmani)\n",
    "plt.yscale('log')\n",
    "plt.legend(title='country', bbox_to_anchor=(1.05, 1), loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "communist-promise",
   "metadata": {},
   "source": [
    "For the domestic withdrawals the difference between countries shrinks and we still see United States as the leader, also it is clear how France is gradually diminishing its withdrawals and Korea too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "typical-asset",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmani = dfreg.copy()\n",
    "dfmani.reset_index(inplace=True)\n",
    "dfmani = dfmani[dfmani['country'].isin(['France', 'United States', 'Korea, Rep.'])]\n",
    "dfmani.sort_values(['date', 'country'], inplace=True)\n",
    "dfmani.head()\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.lineplot(x='date', y='wtrwthdompc', hue='country', data=dfmani)\n",
    "plt.yscale('log')\n",
    "plt.legend(title='country', bbox_to_anchor=(1.05, 1), loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "waiting-conversion",
   "metadata": {},
   "source": [
    "Finally, we can check the industrial sector and see a very different pattern. As we said before, it is clear that Korea is more focused in agricultural than in industrial activites in relative terms to France, which is now above the Asian country in water withdrawals per capita. Anyway, United States reaches once again the highest values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contrary-refund",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmani = dfreg.copy()\n",
    "dfmani.reset_index(inplace=True)\n",
    "dfmani = dfmani[dfmani['country'].isin(['France', 'United States', 'Korea, Rep.'])]\n",
    "dfmani.sort_values(['date', 'country'], inplace=True)\n",
    "dfmani.head()\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.lineplot(x='date', y='wtrwthindpc', hue='country', data=dfmani)\n",
    "plt.yscale('log')\n",
    "plt.legend(title='country', bbox_to_anchor=(1.05, 1), loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "balanced-graphic",
   "metadata": {},
   "source": [
    "#### Final dataset fixing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analyzed-upset",
   "metadata": {},
   "source": [
    "We now make sure that the time index has a numeric data type and the entity an object form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demanding-webmaster",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specifying the data types of the index components\n",
    "date = dfreg.index.levels[1].astype(int)\n",
    "country = dfreg.index.levels[0].astype(object)\n",
    "dfreg.index = dfreg.index.set_levels([country, date])\n",
    "dfreg.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "monthly-compound",
   "metadata": {},
   "source": [
    "For the regressions, we also need to include both the independent and dependent variables in their logarithm form, so as to linearize the variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sealed-answer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding the log terms to the regression dataframe\n",
    "columns = ['wtrwthpc', 'gdppc', 'wtrwthagpc', 'wtrwthdompc', 'wtrwthindpc']\n",
    "for col in columns:\n",
    "    dfreg[\"log-\" + col] = np.log(dfreg[col])\n",
    "dfreg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "burning-samba",
   "metadata": {},
   "source": [
    "The same happens with the quadratic term that we need for the GDPpc variable in order to include this specification of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "living-button",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding the squared term to the regression dataframe\n",
    "for col in ['log-gdppc']:\n",
    "    dfreg['sq_' + col] = np.square(dfreg[col])\n",
    "    \n",
    "dfreg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tested-bulgaria",
   "metadata": {},
   "source": [
    "## PANEL DATA REGRESSIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "transparent-adaptation",
   "metadata": {},
   "source": [
    "Next, we start with the regression analysis itself. Although we are going to do a panel regression, we start by executing a pooled OLS analysis to be able to test for homoskedasticity and serial autocorrelation, which are some of the assumptions related to a recommended use of fixed or random effects regressions rather than simple OLS regressions. In this sense, if we found no presence of heteroskedasticity or serial autocorrelation we would not be in the need of running a fixed or random effect regression. However, as we will see, none of these assumptions hold for a pooled OLS regression to be the ideal option, so we then perform the fixed and random effect regressions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olympic-press",
   "metadata": {},
   "source": [
    "### LINEAR REGRESSIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "framed-jamaica",
   "metadata": {},
   "source": [
    "We then start by declaring the independent ($GDPpc_{it}$) and dependent ($WATER_{it}$). We then perform the regression and store the residuals values for analysing whether there is or not homoskedasticity. We show a scatter plot of the residuals in order to see the way they are shaped. In this case, there is not a clear patter, which would make us contemplate heteroskedasticity as more likely. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ambient-bridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting the indepent and dependent variables\n",
    "from linearmodels import PooledOLS\n",
    "exog = sm.add_constant(dfreg['log-gdppc'])\n",
    "endog = dfreg['log-wtrwthpc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "particular-conversation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pooled OLS for homoskedasticity \n",
    "mod = PooledOLS(endog, exog)\n",
    "pooledOLS_res = mod.fit(cov_type='clustered', cluster_entity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hazardous-isaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store values for checking homoskedasticity graphically\n",
    "fittedvals_pooled_OLS = pooledOLS_res.predict().fitted_values\n",
    "residuals_pooled_OLS = pooledOLS_res.resids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "front-boston",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Homoskedasticity\n",
    "#Residuals-Plot for growing Variance Detection\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(fittedvals_pooled_OLS, residuals_pooled_OLS, color = 'green')\n",
    "ax.axhline(0, color = 'b', ls = '--')\n",
    "ax.set_xlabel('Predicted Values', fontsize = 10)\n",
    "ax.set_ylabel('Residuals', fontsize = 10)\n",
    "ax.set_title('Homoskedasticity Test', fontsize = 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "personalized-senate",
   "metadata": {},
   "source": [
    "However, for making sure that this is the case, we execute both the White and the Breusch-Pagan tests, for which the null hypotheses are both that there is evidence of homoskedasticity. In both cases the p-value is below 0.05, which indicates that the null hypothesis can be rejected and there is no evidence of homoskedasticity, and then there is evidence of heteroskedasticity in the errors terms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unable-midnight",
   "metadata": {},
   "outputs": [],
   "source": [
    "#White-Test\n",
    "pooled_OLS_dataset = pd.concat([dfreg, residuals_pooled_OLS], axis=1)\n",
    "exog = sm.tools.tools.add_constant(dfreg['log-gdppc']).fillna(0)\n",
    "white_test_results = het_white(pooled_OLS_dataset['residual'], exog)\n",
    "labels = ['LM-Stat', 'LM p-val', 'F-Stat', 'F p-val'] \n",
    "print(dict(zip(labels, white_test_results)))\n",
    "\n",
    "#Breusch-Pagan-Test\n",
    "breusch_pagan_test_results = het_breuschpagan(pooled_OLS_dataset['residual'], exog)\n",
    "labels = ['LM-Stat', 'LM p-val', 'F-Stat', 'F p-val'] \n",
    "print(dict(zip(labels, breusch_pagan_test_results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elegant-vertical",
   "metadata": {},
   "source": [
    "Subsequently, we look for serial correlation. For this matter we perform a Durbin-Watson test. The Durbin-Watson test will have one output between 0 ‚Äì 4. The mean (= 2) would indicate that there is no autocorrelation identified, 0 ‚Äì 2 means positive autocorrelation (the nearer to zero the higher the correlation), and 2 ‚Äì 4 means negative autocorrelation (the nearer to four the higher the correlation). We then find out that the value shows a strong positive correlation. All in all, we must then privilege the application of fixed (or random) effects regressions rather than OLS ones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "black-ownership",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Non-Autocorrelation\n",
    "# Durbin-Watson-Test\n",
    "durbin_watson_test_results = durbin_watson(pooled_OLS_dataset['residual']) \n",
    "print(durbin_watson_test_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enclosed-explanation",
   "metadata": {},
   "source": [
    "We then use the PanelOLS and RandomEffects specifications to do the analysis. The output shows that in both regressions the variables are strongly significant, and that the GDP per capita variable is negative. While the R-squared is higher for the random effects model, the log-likelihood shows to be better for the fixed effects. Anyway, both specifications show similar results and according to what was previously stated we rather stick to the fixed effects for theoretical coherence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "backed-stick",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FE und RE model\n",
    "exog = sm.add_constant(dfreg['log-gdppc'])\n",
    "endog = dfreg['log-wtrwthpc']\n",
    "# random effects model\n",
    "model_re = RandomEffects(endog, exog) \n",
    "re_res = model_re.fit() \n",
    "# fixed effects model\n",
    "model_fe = PanelOLS(endog, exog, entity_effects = True) \n",
    "fe_res = model_fe.fit() \n",
    "#print results\n",
    "print(re_res)\n",
    "print(fe_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intense-helen",
   "metadata": {},
   "source": [
    "Finally, we perform a Hausman test in which we can conclude whether fixed or random effects are more convenient. The null hypothesis is that random effects are the preferred option and the alternative otherwise. In this case the p-value>0.05, so that we would not be able to reject the null hypothesis. However, as we have said already, it would make more sense to use a fixed-effect approach for theoretical coherence. This test shows that random effect would nonetheless be a good option for the present case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atmospheric-emission",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hausman test\n",
    "def hausman(fe, re):\n",
    "    b = fe.params\n",
    "    B = re.params\n",
    "    v_b = fe.cov\n",
    "    v_B = re.cov\n",
    "    df = b[np.abs(b) < 1e8].size\n",
    "    chi2 = np.dot((b - B).T, la.inv(v_b - v_B).dot(b - B)) \n",
    " \n",
    "    pval = stats.chi2.sf(chi2, df)\n",
    "    return chi2, df, pval\n",
    "hausman_results = hausman(fe_res, re_res) \n",
    "print('chi-Squared: '  + str(hausman_results[0]))\n",
    "print('degrees of freedom: ' + str(hausman_results[1]))\n",
    "print('p-Value: ' + str(hausman_results[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deluxe-lunch",
   "metadata": {},
   "source": [
    "#### SECTOR ANALYSIS: AGRICULTURAL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stock-element",
   "metadata": {},
   "source": [
    "We then take into account the agricultural water withdrawals instead of the total ones. The procedure is the same as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handled-processor",
   "metadata": {},
   "outputs": [],
   "source": [
    "exog = sm.add_constant(dfreg['log-gdppc'])\n",
    "endog = dfreg['log-wtrwthagpc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "perfect-entrepreneur",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = PooledOLS(endog, exog)\n",
    "pooledOLS_res = mod.fit(cov_type='clustered', cluster_entity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exact-ownership",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store values for checking homoskedasticity graphically\n",
    "fittedvals_pooled_OLS = pooledOLS_res.predict().fitted_values\n",
    "residuals_pooled_OLS = pooledOLS_res.resids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "general-singing",
   "metadata": {},
   "source": [
    "Again, the graph does not show a clear pattern, but the dots seem to be slightly more equally distributed than in the previous scenario. When we perform the tests, we see that indeed the p-value is not lower than 0.05 but since it can still be considered as significant (p-value<0.1) we cannot rule out the presence of heteroskedasticity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "white-philip",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Homoskedasticity\n",
    "#Residuals-Plot for growing Variance Detection\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(fittedvals_pooled_OLS, residuals_pooled_OLS, color = 'green')\n",
    "ax.axhline(0, color = 'b', ls = '--')\n",
    "ax.set_xlabel('Predicted Values', fontsize = 10)\n",
    "ax.set_ylabel('Residuals', fontsize = 10)\n",
    "ax.set_title('Homoskedasticity Test', fontsize = 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monthly-state",
   "metadata": {},
   "outputs": [],
   "source": [
    "#White-Test\n",
    "pooled_OLS_dataset = pd.concat([dfreg, residuals_pooled_OLS], axis=1)\n",
    "exog = sm.tools.tools.add_constant(dfreg['log-gdppc']).fillna(0)\n",
    "white_test_results = het_white(pooled_OLS_dataset['residual'], exog)\n",
    "labels = ['LM-Stat', 'LM p-val', 'F-Stat', 'F p-val'] \n",
    "print(dict(zip(labels, white_test_results)))\n",
    "\n",
    "#Breusch-Pagan-Test\n",
    "breusch_pagan_test_results = het_breuschpagan(pooled_OLS_dataset['residual'], exog)\n",
    "labels = ['LM-Stat', 'LM p-val', 'F-Stat', 'F p-val'] \n",
    "print(dict(zip(labels, breusch_pagan_test_results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animated-citizen",
   "metadata": {},
   "source": [
    "Serial autocorrelation is again present as the high correlation positive value shows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applicable-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Non-Autocorrelation\n",
    "# Durbin-Watson-Test\n",
    "durbin_watson_test_results = durbin_watson(pooled_OLS_dataset['residual']) \n",
    "print(durbin_watson_test_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clean-coverage",
   "metadata": {},
   "source": [
    "In both the following regressions the coefficients are again strongly significant and negative, and we can see the same characteristics of the R-squared and log-likelihood as in the previous case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "first-notification",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FE und RE model\n",
    "exog = sm.add_constant(dfreg['log-gdppc'])\n",
    "endog = dfreg['log-wtrwthagpc']\n",
    "# random effects model\n",
    "model_re = RandomEffects(endog, exog) \n",
    "re_res = model_re.fit() \n",
    "# fixed effects model\n",
    "model_fe = PanelOLS(endog, exog, entity_effects = True) \n",
    "fe_res = model_fe.fit() \n",
    "#print results\n",
    "print(re_res)\n",
    "print(fe_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smooth-stamp",
   "metadata": {},
   "source": [
    "The Hausman test again indicates a preferred use of random effects, showing the importance of taking into account the difference between a purely statistic scope and a theory-based one, since the outcomes can vary a lot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "younger-smoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hausman(fe, re):\n",
    "    b = fe.params\n",
    "    B = re.params\n",
    "    v_b = fe.cov\n",
    "    v_B = re.cov\n",
    "    df = b[np.abs(b) < 1e8].size\n",
    "    chi2 = np.dot((b - B).T, la.inv(v_b - v_B).dot(b - B)) \n",
    " \n",
    "    pval = stats.chi2.sf(chi2, df)\n",
    "    return chi2, df, pval\n",
    "hausman_results = hausman(fe_res, re_res) \n",
    "print('chi-Squared:'  + str(hausman_results[0]))\n",
    "print('degrees of freedom:' + str(hausman_results[1]))\n",
    "print('p-Value: ' + str(hausman_results[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "super-spell",
   "metadata": {},
   "source": [
    "#### SECTOR ANALYSIS: DOMESTIC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alien-footage",
   "metadata": {},
   "source": [
    "Now we then take into account the domestic water withdrawals instead of the total ones. The procedure is once more the same as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modified-imagination",
   "metadata": {},
   "outputs": [],
   "source": [
    "exog = sm.add_constant(dfreg['log-gdppc'])\n",
    "endog = dfreg['log-wtrwthdompc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cosmetic-intelligence",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = PooledOLS(endog, exog)\n",
    "pooledOLS_res = mod.fit(cov_type='clustered', cluster_entity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressing-pregnancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store values for checking homoskedasticity graphically\n",
    "fittedvals_pooled_OLS = pooledOLS_res.predict().fitted_values\n",
    "residuals_pooled_OLS = pooledOLS_res.resids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "premier-resource",
   "metadata": {},
   "source": [
    "Again, the graph does not show a clear pattern although the dots are more concentrated. Both the tests lead us again to conclude that heteroskedasticity cannot be ruled out (p-value<0). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ahead-broadcasting",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Homoskedasticity\n",
    "#Residuals-Plot for growing Variance Detection\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(fittedvals_pooled_OLS, residuals_pooled_OLS, color = 'green')\n",
    "ax.axhline(0, color = 'b', ls = '--')\n",
    "ax.set_xlabel('Predicted Values', fontsize = 10)\n",
    "ax.set_ylabel('Residuals', fontsize = 10)\n",
    "ax.set_title('Homoskedasticity Test', fontsize = 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "resistant-growth",
   "metadata": {},
   "outputs": [],
   "source": [
    "#White-Test\n",
    "pooled_OLS_dataset = pd.concat([dfreg, residuals_pooled_OLS], axis=1)\n",
    "exog = sm.tools.tools.add_constant(dfreg['log-gdppc']).fillna(0)\n",
    "white_test_results = het_white(pooled_OLS_dataset['residual'], exog)\n",
    "labels = ['LM-Stat', 'LM p-val', 'F-Stat', 'F p-val'] \n",
    "print(dict(zip(labels, white_test_results)))\n",
    "\n",
    "#Breusch-Pagan-Test\n",
    "breusch_pagan_test_results = het_breuschpagan(pooled_OLS_dataset['residual'], exog)\n",
    "labels = ['LM-Stat', 'LM p-val', 'F-Stat', 'F p-val'] \n",
    "print(dict(zip(labels, breusch_pagan_test_results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "behavioral-conviction",
   "metadata": {},
   "source": [
    "Serial autocorrelation is once again positive and strong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "normal-twenty",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Non-Autocorrelation\n",
    "# Durbin-Watson-Test\n",
    "durbin_watson_test_results = durbin_watson(pooled_OLS_dataset['residual']) \n",
    "print(durbin_watson_test_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pending-forth",
   "metadata": {},
   "source": [
    "For the regressions, we find a difference now, as only the fixed-effects specification shows a significant coefficient for GDP pc, and it is again negative. Logically, the Hausman test now shows a preference for fixed-effects (p-value<0.5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iraqi-doctrine",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FE und RE model\n",
    "exog = sm.add_constant(dfreg['log-gdppc'])\n",
    "endog = dfreg['log-wtrwthdompc']\n",
    "# random effects model\n",
    "model_re = RandomEffects(endog, exog) \n",
    "re_res = model_re.fit() \n",
    "# fixed effects model\n",
    "model_fe = PanelOLS(endog, exog, entity_effects = True) \n",
    "fe_res = model_fe.fit() \n",
    "#print results\n",
    "print(re_res)\n",
    "print(fe_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "split-stereo",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hausman(fe, re):\n",
    "    b = fe.params\n",
    "    B = re.params\n",
    "    v_b = fe.cov\n",
    "    v_B = re.cov\n",
    "    df = b[np.abs(b) < 1e8].size\n",
    "    chi2 = np.dot((b - B).T, la.inv(v_b - v_B).dot(b - B)) \n",
    " \n",
    "    pval = stats.chi2.sf(chi2, df)\n",
    "    return chi2, df, pval\n",
    "hausman_results = hausman(fe_res, re_res) \n",
    "print('chi-Squared:'  + str(hausman_results[0]))\n",
    "print('degrees of freedom:' + str(hausman_results[1]))\n",
    "print('p-Value: ' + str(hausman_results[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corrected-budapest",
   "metadata": {},
   "source": [
    "#### SECTOR ANALYSIS: INDUSTRIAL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cellular-artwork",
   "metadata": {},
   "source": [
    "Finally, we analyse the industrial water withdrawals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disturbed-jumping",
   "metadata": {},
   "outputs": [],
   "source": [
    "exog = sm.add_constant(dfreg['log-gdppc'])\n",
    "endog = dfreg['log-wtrwthindpc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "completed-serial",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = PooledOLS(endog, exog)\n",
    "pooledOLS_res = mod.fit(cov_type='clustered', cluster_entity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "registered-balance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store values for checking homoskedasticity graphically\n",
    "fittedvals_pooled_OLS = pooledOLS_res.predict().fitted_values\n",
    "residuals_pooled_OLS = pooledOLS_res.resids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "literary-license",
   "metadata": {},
   "source": [
    "The scatter plot is again diffuse and both White and Breusch-Pagan tests show small p-values, which indicates that heteroskedasticity in the error terms cannot be discarded. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "molecular-school",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Homoskedasticity\n",
    "#Residuals-Plot for growing Variance Detection\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(fittedvals_pooled_OLS, residuals_pooled_OLS, color = 'green')\n",
    "ax.axhline(0, color = 'b', ls = '--')\n",
    "ax.set_xlabel('Predicted Values', fontsize = 10)\n",
    "ax.set_ylabel('Residuals', fontsize = 10)\n",
    "ax.set_title('Homoskedasticity Test', fontsize = 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distributed-magnitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "#White-Test\n",
    "pooled_OLS_dataset = pd.concat([dfreg, residuals_pooled_OLS], axis=1)\n",
    "exog = sm.tools.tools.add_constant(dfreg['log-gdppc']).fillna(0)\n",
    "white_test_results = het_white(pooled_OLS_dataset['residual'], exog)\n",
    "labels = ['LM-Stat', 'LM p-val', 'F-Stat', 'F p-val'] \n",
    "print(dict(zip(labels, white_test_results)))\n",
    "\n",
    "#Breusch-Pagan-Test\n",
    "breusch_pagan_test_results = het_breuschpagan(pooled_OLS_dataset['residual'], exog)\n",
    "labels = ['LM-Stat', 'LM p-val', 'F-Stat', 'F p-val'] \n",
    "print(dict(zip(labels, breusch_pagan_test_results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "computational-regulation",
   "metadata": {},
   "source": [
    "Autocorrelation is positive and strong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustainable-throw",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Non-Autocorrelation\n",
    "# Durbin-Watson-Test\n",
    "\n",
    "durbin_watson_test_results = durbin_watson(pooled_OLS_dataset['residual']) \n",
    "print(durbin_watson_test_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "magnetic-equation",
   "metadata": {},
   "source": [
    "The output shows highly significant coefficients for both specifications, but the Hausman test corroborates this time the use of fixed effects (p-value<0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certified-presence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FE und RE model\n",
    "exog = sm.add_constant(dfreg['log-gdppc'])\n",
    "endog = dfreg['log-wtrwthindpc']\n",
    "# random effects model\n",
    "model_re = RandomEffects(endog, exog) \n",
    "re_res = model_re.fit() \n",
    "# fixed effects model\n",
    "model_fe = PanelOLS(endog, exog, entity_effects = True) \n",
    "fe_res = model_fe.fit() \n",
    "#print results\n",
    "print(re_res)\n",
    "print(fe_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finished-basics",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hausman(fe, re):\n",
    "    b = fe.params\n",
    "    B = re.params\n",
    "    v_b = fe.cov\n",
    "    v_B = re.cov\n",
    "    df = b[np.abs(b) < 1e8].size\n",
    "    chi2 = np.dot((b - B).T, la.inv(v_b - v_B).dot(b - B)) \n",
    " \n",
    "    pval = stats.chi2.sf(chi2, df)\n",
    "    return chi2, df, pval\n",
    "hausman_results = hausman(fe_res, re_res) \n",
    "print('chi-Squared:'  + str(hausman_results[0]))\n",
    "print('degrees of freedom:' + str(hausman_results[1]))\n",
    "print('p-Value: ' + str(hausman_results[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "international-meter",
   "metadata": {},
   "source": [
    " ### QUADRATIC MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustained-classic",
   "metadata": {},
   "source": [
    "In order to further approach the inverted-U shape of the EKC, we now perform a quadratic variation of the previous regressions. All the steps are conducted the same way as before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indie-accountability",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting the indepent and dependent variables\n",
    "exog_vars = ['log-gdppc','sq_log-gdppc']\n",
    "exog = sm.add_constant(dfreg[exog_vars])\n",
    "endog = dfreg['log-wtrwthpc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "global-wilderness",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pooled OLS for homoskedasticity \n",
    "mod = PooledOLS(endog, exog)\n",
    "pooledOLS_res = mod.fit(cov_type='clustered', cluster_entity=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assumed-spanish",
   "metadata": {},
   "source": [
    "We include a graph that shows that the data follows a parabolic trend using the seaborn tool. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "waiting-basics",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(color_codes=True)\n",
    "sns.regplot(x=\"log-gdppc\", y=\"log-wtrwthpc\", data=dfreg, order=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structural-equipment",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store values for checking homoskedasticity graphically\n",
    "fittedvals_pooled_OLS = pooledOLS_res.predict().fitted_values\n",
    "residuals_pooled_OLS = pooledOLS_res.resids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automotive-california",
   "metadata": {},
   "source": [
    "The homoskedasticity graph is not concluding and the White and Breusch-Pagan tests show different p-values, the first one indicating the presence of heteroskedasticity and the second one not doing so. Facing this ambiguity, it is not possible to totally discard heteroskedasticity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "friendly-world",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Homoskedasticity\n",
    "#Residuals-Plot for growing Variance Detection\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(fittedvals_pooled_OLS, residuals_pooled_OLS, color = 'green')\n",
    "ax.axhline(0, color = 'b', ls = '--')\n",
    "ax.set_xlabel('Predicted Values', fontsize = 10)\n",
    "ax.set_ylabel('Residuals', fontsize = 10)\n",
    "ax.set_title('Homoskedasticity Test', fontsize = 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legal-proof",
   "metadata": {},
   "outputs": [],
   "source": [
    "#White-Test\n",
    "pooled_OLS_dataset = pd.concat([dfreg, residuals_pooled_OLS], axis=1)\n",
    "exog = sm.tools.tools.add_constant(dfreg[exog_vars]).fillna(0)\n",
    "white_test_results = het_white(pooled_OLS_dataset['residual'], exog)\n",
    "labels = ['LM-Stat', 'LM p-val', 'F-Stat', 'F p-val'] \n",
    "print(dict(zip(labels, white_test_results)))\n",
    "\n",
    "#Breusch-Pagan-Test\n",
    "breusch_pagan_test_results = het_breuschpagan(pooled_OLS_dataset['residual'], exog)\n",
    "labels = ['LM-Stat', 'LM p-val', 'F-Stat', 'F p-val'] \n",
    "print(dict(zip(labels, breusch_pagan_test_results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functioning-apartment",
   "metadata": {},
   "source": [
    "Autocorrelation is positive and strong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "correct-mapping",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Non-Autocorrelation\n",
    "# Durbin-Watson-Test\n",
    "durbin_watson_test_results = durbin_watson(pooled_OLS_dataset['residual']) \n",
    "print(durbin_watson_test_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "headed-violation",
   "metadata": {},
   "source": [
    "The regressions outcome shows a lack of significance for all the coefficients in both specifications so we cannot really prove that there exists a relationship between GDPpc and water withdrawals in this case. The Hausman test is thus not performed because it works to decide which model is best when both yield representative results, and this is not the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stretch-navigator",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FE und RE model\n",
    "exog_vars = ['log-gdppc','sq_log-gdppc']\n",
    "exog = sm.add_constant(dfreg[exog_vars])\n",
    "endog = dfreg['log-wtrwthpc']\n",
    "# random effects model\n",
    "model_re = RandomEffects(endog, exog) \n",
    "re_res = model_re.fit() \n",
    "# fixed effects model\n",
    "model_fe = PanelOLS(endog, exog, entity_effects = True) \n",
    "fe_res = model_fe.fit() \n",
    "#print results\n",
    "print(re_res)\n",
    "print(fe_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appropriate-potential",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hausman test\n",
    "def hausman(fe, re):\n",
    "    b = fe.params\n",
    "    B = re.params\n",
    "    v_b = fe.cov\n",
    "    v_B = re.cov\n",
    "    df = b[np.abs(b) < 1e8].size\n",
    "    chi2 = np.dot((b - B).T, la.inv(v_b - v_B).dot(b - B)) \n",
    " \n",
    "    pval = stats.chi2.sf(chi2, df)\n",
    "    return chi2, df, pval\n",
    "hausman_results = hausman(fe_res, re_res) \n",
    "print('chi-Squared: '  + str(hausman_results[0]))\n",
    "print('degrees of freedom: ' + str(hausman_results[1]))\n",
    "print('p-Value: ' + str(hausman_results[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indoor-radiation",
   "metadata": {},
   "source": [
    "#### SECTOR ANALYSIS: AGRICULTURAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vietnamese-questionnaire",
   "metadata": {},
   "outputs": [],
   "source": [
    "exog_vars = ['log-gdppc','sq_log-gdppc']\n",
    "exog = sm.add_constant(dfreg[exog_vars])\n",
    "endog = dfreg['log-wtrwthagpc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyzed-portal",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = PooledOLS(endog, exog)\n",
    "pooledOLS_res = mod.fit(cov_type='clustered', cluster_entity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tracked-certificate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store values for checking homoskedasticity graphically\n",
    "fittedvals_pooled_OLS = pooledOLS_res.predict().fitted_values\n",
    "residuals_pooled_OLS = pooledOLS_res.resids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceramic-pierre",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Homoskedasticity\n",
    "#Residuals-Plot for growing Variance Detection\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(fittedvals_pooled_OLS, residuals_pooled_OLS, color = 'green')\n",
    "ax.axhline(0, color = 'b', ls = '--')\n",
    "ax.set_xlabel('Predicted Values', fontsize = 10)\n",
    "ax.set_ylabel('Residuals', fontsize = 10)\n",
    "ax.set_title('Homoskedasticity Test', fontsize = 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "patient-buying",
   "metadata": {},
   "source": [
    "For the case of the agricultural specification again we cannot discard heteroskedasticity in the error terms although we have the same situation as before, the White and the Breusch-Pagan tests contradict themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funky-slave",
   "metadata": {},
   "outputs": [],
   "source": [
    "#White-Test\n",
    "pooled_OLS_dataset = pd.concat([dfreg, residuals_pooled_OLS], axis=1)\n",
    "exog = sm.tools.tools.add_constant(dfreg[exog_vars]).fillna(0)\n",
    "white_test_results = het_white(pooled_OLS_dataset['residual'], exog)\n",
    "labels = ['LM-Stat', 'LM p-val', 'F-Stat', 'F p-val'] \n",
    "print(dict(zip(labels, white_test_results)))\n",
    "\n",
    "#Breusch-Pagan-Test\n",
    "breusch_pagan_test_results = het_breuschpagan(pooled_OLS_dataset['residual'], exog)\n",
    "labels = ['LM-Stat', 'LM p-val', 'F-Stat', 'F p-val'] \n",
    "print(dict(zip(labels, breusch_pagan_test_results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intellectual-group",
   "metadata": {},
   "source": [
    "Again, autocorrelation is positive and even stronger than befroe, which leads us once again to preferring the panel specifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpha-generator",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Non-Autocorrelation\n",
    "# Durbin-Watson-Test\n",
    "durbin_watson_test_results = durbin_watson(pooled_OLS_dataset['residual']) \n",
    "print(durbin_watson_test_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consistent-jesus",
   "metadata": {},
   "source": [
    "This time, all the coefficients are found to be significant in both specifications and while the linear term is positive the quadratic one is not, which is consistent with the EKC shape. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocational-platform",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FE und RE model\n",
    "exog_vars = ['log-gdppc','sq_log-gdppc']\n",
    "exog = sm.add_constant(dfreg[exog_vars])\n",
    "endog = dfreg['log-wtrwthagpc']\n",
    "# random effects model\n",
    "model_re = RandomEffects(endog, exog) \n",
    "re_res = model_re.fit() \n",
    "# fixed effects model\n",
    "model_fe = PanelOLS(endog, exog, entity_effects = True) \n",
    "fe_res = model_fe.fit() \n",
    "#print results\n",
    "print(re_res)\n",
    "print(fe_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "environmental-transaction",
   "metadata": {},
   "source": [
    "The Hausman test does not support the use of fixed effects but, as we have already done numerous times, the preferred fixed specification is used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "provincial-darwin",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hausman(fe, re):\n",
    "    b = fe.params\n",
    "    B = re.params\n",
    "    v_b = fe.cov\n",
    "    v_B = re.cov\n",
    "    df = b[np.abs(b) < 1e8].size\n",
    "    chi2 = np.dot((b - B).T, la.inv(v_b - v_B).dot(b - B)) \n",
    " \n",
    "    pval = stats.chi2.sf(chi2, df)\n",
    "    return chi2, df, pval\n",
    "hausman_results = hausman(fe_res, re_res) \n",
    "print('chi-Squared:'  + str(hausman_results[0]))\n",
    "print('degrees of freedom:' + str(hausman_results[1]))\n",
    "print('p-Value: ' + str(hausman_results[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brown-layer",
   "metadata": {},
   "source": [
    "##### CALCULATING THE TURNING POINT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "previous-mortgage",
   "metadata": {},
   "source": [
    "We now can use these significant coefficients for the estimation of the turning point, that is calculated as follows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fantastic-apparel",
   "metadata": {},
   "outputs": [],
   "source": [
    "fe_coeffs=fe_res.params\n",
    "turn_point=np.exp(-fe_coeffs[1]/(2*fe_coeffs[2]))\n",
    "print(turn_point)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marked-spencer",
   "metadata": {},
   "source": [
    "This gives us a turning point of $11,121.72, which is consistent with other studies that have performed this kind of analysis.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nearby-mechanics",
   "metadata": {},
   "source": [
    "#### SECTOR ANALYSIS: DOMESTIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contemporary-target",
   "metadata": {},
   "outputs": [],
   "source": [
    "exog_vars = ['log-gdppc','sq_log-gdppc']\n",
    "exog = sm.add_constant(dfreg[exog_vars])\n",
    "endog = dfreg['log-wtrwthdompc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protecting-prison",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = PooledOLS(endog, exog)\n",
    "pooledOLS_res = mod.fit(cov_type='clustered', cluster_entity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genetic-malpractice",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store values for checking homoskedasticity graphically\n",
    "fittedvals_pooled_OLS = pooledOLS_res.predict().fitted_values\n",
    "residuals_pooled_OLS = pooledOLS_res.resids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specialized-matthew",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Homoskedasticity\n",
    "#Residuals-Plot for growing Variance Detection\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(fittedvals_pooled_OLS, residuals_pooled_OLS, color = 'green')\n",
    "ax.axhline(0, color = 'b', ls = '--')\n",
    "ax.set_xlabel('Predicted Values', fontsize = 10)\n",
    "ax.set_ylabel('Residuals', fontsize = 10)\n",
    "ax.set_title('Homoskedasticity Test', fontsize = 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "romantic-appointment",
   "metadata": {},
   "source": [
    "The White and Breusch-Pagan show contradictory results again, but since the Breusch-Pagan p-value (<0.5) leads us to reject the null hypothesis we cannot say that there is no evidence of heteroskedasticity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generic-invention",
   "metadata": {},
   "outputs": [],
   "source": [
    "#White-Test\n",
    "pooled_OLS_dataset = pd.concat([dfreg, residuals_pooled_OLS], axis=1)\n",
    "exog = sm.tools.tools.add_constant(dfreg[exog_vars]).fillna(0)\n",
    "white_test_results = het_white(pooled_OLS_dataset['residual'], exog)\n",
    "labels = ['LM-Stat', 'LM p-val', 'F-Stat', 'F p-val'] \n",
    "print(dict(zip(labels, white_test_results)))\n",
    "\n",
    "#Breusch-Pagan-Test\n",
    "breusch_pagan_test_results = het_breuschpagan(pooled_OLS_dataset['residual'], exog)\n",
    "labels = ['LM-Stat', 'LM p-val', 'F-Stat', 'F p-val'] \n",
    "print(dict(zip(labels, breusch_pagan_test_results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "everyday-trigger",
   "metadata": {},
   "source": [
    "The autocorrelation is again positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transparent-laptop",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Non-Autocorrelation\n",
    "# Durbin-Watson-Test\n",
    "durbin_watson_test_results = durbin_watson(pooled_OLS_dataset['residual']) \n",
    "print(durbin_watson_test_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turkish-dynamics",
   "metadata": {},
   "source": [
    "In both the regressions only the constant term is significant at 10%, so we cannot conclude that it shows a relationship between water withdrawals and GDPpc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "united-seller",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FE und RE model\n",
    "exog_vars = ['log-gdppc','sq_log-gdppc']\n",
    "exog = sm.add_constant(dfreg[exog_vars])\n",
    "endog = dfreg['log-wtrwthdompc']\n",
    "# random effects model\n",
    "model_re = RandomEffects(endog, exog) \n",
    "re_res = model_re.fit() \n",
    "# fixed effects model\n",
    "model_fe = PanelOLS(endog, exog, entity_effects = True) \n",
    "fe_res = model_fe.fit() \n",
    "#print results\n",
    "print(re_res)\n",
    "print(fe_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lovely-threshold",
   "metadata": {},
   "source": [
    "#### SECTOR ANALYSIS: INDUSTRIAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "operational-jumping",
   "metadata": {},
   "outputs": [],
   "source": [
    "exog_vars = ['log-gdppc','sq_log-gdppc']\n",
    "exog = sm.add_constant(dfreg[exog_vars])\n",
    "endog = dfreg['log-wtrwthindpc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlling-implement",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = PooledOLS(endog, exog)\n",
    "pooledOLS_res = mod.fit(cov_type='clustered', cluster_entity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premium-embassy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store values for checking homoskedasticity graphically\n",
    "fittedvals_pooled_OLS = pooledOLS_res.predict().fitted_values\n",
    "residuals_pooled_OLS = pooledOLS_res.resids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prescribed-somalia",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Homoskedasticity\n",
    "#Residuals-Plot for growing Variance Detection\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(fittedvals_pooled_OLS, residuals_pooled_OLS, color = 'green')\n",
    "ax.axhline(0, color = 'b', ls = '--')\n",
    "ax.set_xlabel('Predicted Values', fontsize = 10)\n",
    "ax.set_ylabel('Residuals', fontsize = 10)\n",
    "ax.set_title('Homoskedasticity Test', fontsize = 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suitable-seeker",
   "metadata": {},
   "source": [
    "This time we can conclude that there is evidence of presence of heteroskedasticity in the residuals at a level of significance of 10% for the White test and 5% for the Breusch-Pagan test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graphic-rebate",
   "metadata": {},
   "outputs": [],
   "source": [
    "#White-Test\n",
    "pooled_OLS_dataset = pd.concat([dfreg, residuals_pooled_OLS], axis=1)\n",
    "exog = sm.tools.tools.add_constant(dfreg[exog_vars]).fillna(0)\n",
    "white_test_results = het_white(pooled_OLS_dataset['residual'], exog)\n",
    "labels = ['LM-Stat', 'LM p-val', 'F-Stat', 'F p-val'] \n",
    "print(dict(zip(labels, white_test_results)))\n",
    "\n",
    "#Breusch-Pagan-Test\n",
    "breusch_pagan_test_results = het_breuschpagan(pooled_OLS_dataset['residual'], exog)\n",
    "labels = ['LM-Stat', 'LM p-val', 'F-Stat', 'F p-val'] \n",
    "print(dict(zip(labels, breusch_pagan_test_results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "champion-failure",
   "metadata": {},
   "source": [
    "Autocorrelation is positive and strong again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "requested-robert",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Non-Autocorrelation\n",
    "# Durbin-Watson-Test\n",
    "durbin_watson_test_results = durbin_watson(pooled_OLS_dataset['residual']) \n",
    "print(durbin_watson_test_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "billion-alias",
   "metadata": {},
   "source": [
    "The regressions output shows again a lack of significance in all the exogenous variables, so again we cannot state that there is a relationship between those and the endogenous one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latin-postcard",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FE und RE model\n",
    "exog_vars = ['log-gdppc','sq_log-gdppc']\n",
    "exog = sm.add_constant(dfreg[exog_vars])\n",
    "endog = dfreg['log-wtrwthindpc']\n",
    "# random effects model\n",
    "model_re = RandomEffects(endog, exog) \n",
    "re_res = model_re.fit() \n",
    "# fixed effects model\n",
    "model_fe = PanelOLS(endog, exog, entity_effects = True) \n",
    "fe_res = model_fe.fit() \n",
    "#print results\n",
    "print(re_res)\n",
    "print(fe_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "detailed-lemon",
   "metadata": {},
   "source": [
    "# Conclusion:\n",
    "After performing the GLS Regressions we find that the only specification that gives out reasonable values while being significant and also being consistent is the Domestic Water withdrawals for the year 2012 (Sensitivity Analysis) which gives out a value of 10832 which is pretty close to the World Bank threshold for being considered a high income country (12600) dollars. But we have two major problems with the other regressions. The first one is that in the majority of the regressions give out significant values that respect the functional form of the EKC, the problem is that these values are so small that just by common sense shouldn't be taken too seriously. The second problem that we find is that the total water withdrawals for the year 2015 doesn't respect the functional form. We might think that these errors might be due to the structure of the databse or how is it written or maybe due to the presence of other problems like Multicollinearity. We also cannot reject the possibility that choosing another year might change the results and make everything normal. As an example the turning point difference between the 2017 period and 2012 in the case of Domestic Water Withdrawals. <br/>  In the fixed effects panel data is the agriculture withdrawals. we think that we are suffering from the same problems again. <br/> It might be interesting to study the effects of the EKC with other databases as we might see other values than the ones we got."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
